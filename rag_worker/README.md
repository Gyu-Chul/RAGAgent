# **RAG\_Worker: RAGIT의 핵심 기능 처리 시스템**

Rag\_Worker는 GitHub repository의 소스 코드를 자동으로 분석하고 저장한 뒤, 사용자의 자연어 질문을 관련된 코드를 찾아 자동으로 더 나은 프롬프트로 질문하여 향상된 품질의 답을 얻을 수 있도록 돕는 지능형 Q\&A 시스템입니다. 전체 프로세스는 **검색 증강 생성(RAG, Retrieval-Augmented Generation)** 아키텍처를 기반으로 하며, 모든 작업들은 Celery를 통해 비동기적으로 처리됩니다.

## **핵심 아키텍처 및 동작 흐름**

Rag\_Worker의 전체 파이프라인은 **데이터 준비(Indexing)** 단계와 **질의응답(Querying)** 단계로 나뉩니다. 모든 과정은 API 요청에 의해 트리거되며, Celery 워커들이 백그라운드에서 실제 작업을 수행하고 데이터베이스에 진행 상태를 기록합니다.

### **1단계: 저장소 분석 및 벡터화 (Indexing Pipeline)**

사용자가 GitHub 저장소 URL을 입력하면, 시스템은 코드를 이해하고 검색할 수 있는 형태로 가공하는 자동화된 파이프라인을 시작합니다.

#### **1\. 코드 가져오기 (Git Service)**

* **동작**: 사용자가 제공한 URL을 이용해 **Git Service** 가 해당 저장소를 로컬 파일 시스템으로 안전하게 복제(clone)합니다.  
* **결과**: 원본 코드베이스가 서버에 준비됩니다. 동시에, 이 저장소의 벡터 데이터가 저장될 **Milvus Collection** 이 생성됩니다.

#### **2\. 코드 구조 분석 및 조각화 (Python Parser)**

* **동작**: **Python Parser** 가 복제된 저장소 내의 모든 .py 파일을 탐색합니다. **추상 구문 트리(AST, Abstract Syntax Tree)** 분석 기술을 통해 각 파일을 의미 있는 단위(클래스, 함수, 모듈 레벨 코드 등)로 조각냅니다.  
* **결과**: 원본 코드는 구조화된 메타데이터(파일 경로, 정의 타입, 이름, 코드 라인 등)를 포함한 수많은 JSON 객체(청크)로 분해되어 parsed\_repository 폴더에 저장됩니다.

#### **3\. 벡터 임베딩 및 저장 (Vector DB Service)**

* **동작**: **Vector DB Service** 가 파싱된 JSON 청크들을 읽어옵니다. 각 코드 청크의 텍스트 내용은 Hugging Face 언어 모델을 통해 **의미를 나타내는 벡터**(**Dense Vector**)와 **키워드를 나타내는 벡터**(**Sparse Vector**)로 변환됩니다.  
* **결과**: 변환된 벡터들은 코드의 메타데이터와 함께 Milvus 벡터 DB의 해당 Collection에 삽입됩니다. 이로써 코드를 의미 기반 및 키워드 기반으로 검색할 수 있는 준비가 완료됩니다.

### **2단계: 질의응답 및 답변 생성 (RAG Pipeline)**

저장소 분석이 완료되면, 사용자는 자연어 질문을 통해 코드와 관련된 정보를 얻을 수 있습니다.

#### **4\. 지능형 코드 검색 (Vector DB Service)**

* **동작**: 사용자의 질문 역시 의미적 유사성을 찾는 **Dense Vector**와 키워드 일치성을 찾는 **Sparse Vector**로 동시에 변환됩니다. Milvus DB는 이 두 벡터를 사용해 **하이브리드 검색**을 수행하며, 각각의 결과는 **RRF(Reciprocal Rank Fusion)** 랭커에 의해 지능적으로 결합되어 최종 순위가 결정됩니다.
* **결과**: 질문에 대한 답변의 근거가 될 가장 관련성 높은 코드 조각(컨텍스트) 리스트를 확보합니다.

#### **5\. 컨텍스트 기반 프롬프트 생성 (Prompt Generator)**

* **동작**: **Prompt Generator** 가 사용자의 원본 질문과 방금 검색된 코드 조각(컨텍스트)들을 하나의 프롬프트로 지능적으로 결합합니다. 이때 각 코드 조각에는 출처와 관련성 점수 등의 정보가 함께 포함되어 LLM이 컨텍스트를 더 잘 이해하도록 돕습니다.  
* **결과**: AI에게 전달할 최종 질문지, 즉 정교하게 설계된 RAG 프롬프트가 생성됩니다.

#### **6\. 최종 답변 생성 및 저장 (LLM Service)**

* **동작**: **LLM Service** 가 완성된 프롬프트를 OpenAI의 GPT 모델(gpt-4o-mini 등) API로 전송합니다. AI는 주어진 코드 컨텍스트 내에서만 답변을 생성하도록 지시받았기 때문에, 코드에 기반한 정확하고 신뢰도 높은 답변을 생성합니다.  
* **결과**: 생성된 최종 답변은 사용자에게 전달되고, 나중에 다시 조회할 수 있도록 Redis 캐시 또는 데이터베이스에 저장됩니다.