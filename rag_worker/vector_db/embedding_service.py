"""
ì„ë² ë”© ì²˜ë¦¬ ì„œë¹„ìŠ¤
"""

import json
import logging
import os
import time
from typing import Dict, List, Any
import torch
from rank_bm25 import BM25Okapi
from langchain_huggingface import HuggingFaceEmbeddings

from .config import EMBEDDING_MODELS
from .collection_manager import MilvusConnectionManager
from .exceptions import EmbeddingError, DataValidationError, ModelLoadError
from .types import EmbeddingInput, EmbeddingResult

logger = logging.getLogger(__name__)


class BM25ModelCache:
    """BM25 ëª¨ë¸ ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤"""

    _cache: Dict[str, BM25Okapi] = {}

    @classmethod
    def get(cls, collection_name: str) -> BM25Okapi:
        """
        ìºì‹œì—ì„œ BM25 ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°

        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„

        Returns:
            BM25 ëª¨ë¸ (ì—†ìœ¼ë©´ None)
        """
        return cls._cache.get(collection_name)

    @classmethod
    def set(cls, collection_name: str, model: BM25Okapi) -> None:
        """
        ìºì‹œì— BM25 ëª¨ë¸ ì €ì¥

        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            model: BM25 ëª¨ë¸
        """
        cls._cache[collection_name] = model
        logger.info(f"âœ… BM25 model cached for collection: {collection_name}")

    @classmethod
    def has(cls, collection_name: str) -> bool:
        """
        ìºì‹œì— ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸

        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„

        Returns:
            ì¡´ì¬ ì—¬ë¶€
        """
        return collection_name in cls._cache


class DenseEmbedder:
    """ë°€ì§‘ ë²¡í„° ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, model_key: str) -> None:
        """
        DenseEmbedder ì´ˆê¸°í™”

        Args:
            model_key: ëª¨ë¸ í‚¤ (config.EMBEDDING_MODELSì— ì •ì˜ëœ í‚¤)

        Raises:
            ModelLoadError: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ
        """
        self.model_key: str = model_key
        self.model_config: Dict[str, Any] = EMBEDDING_MODELS.get(model_key)

        if not self.model_config:
            raise ModelLoadError(f"Model config not found for key: {model_key}")

        try:
            device: str = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"Loading dense embedding model on device: {device}")

            self.embedder: HuggingFaceEmbeddings = HuggingFaceEmbeddings(
                model_name=self.model_config["model_name"],
                model_kwargs={"device": device, "trust_remote_code": True},
                encode_kwargs={"normalize_embeddings": True},
            )
            logger.info(f"âœ… Dense embedding model loaded: {model_key}")

        except Exception as e:
            logger.error(f"Failed to load dense embedding model: {e}")
            raise ModelLoadError(f"Failed to load model: {e}") from e

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°€ì§‘ ë²¡í„°ë¡œ ë³€í™˜

        Args:
            texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë°€ì§‘ ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        return self.embedder.embed_documents(texts)


class SparseEmbedder:
    """í¬ì†Œ ë²¡í„° ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤ (BM25)"""

    def __init__(self, tokenized_corpus: List[List[str]]) -> None:
        """
        SparseEmbedder ì´ˆê¸°í™”

        Args:
            tokenized_corpus: í† í°í™”ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        self.bm25: BM25Okapi = BM25Okapi(tokenized_corpus)

    def embed_documents(
        self, tokenized_corpus: List[List[str]]
    ) -> List[Dict[int, float]]:
        """
        í† í°í™”ëœ ë¬¸ì„œë¥¼ í¬ì†Œ ë²¡í„°ë¡œ ë³€í™˜

        Args:
            tokenized_corpus: í† í°í™”ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

        Returns:
            í¬ì†Œ ë²¡í„° ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
        """
        sparse_vectors: List[Dict[int, float]] = []

        for doc_tokens in tokenized_corpus:
            doc_scores = self.bm25.get_scores(doc_tokens)
            sparse_vec = {i: score for i, score in enumerate(doc_scores) if score > 0}
            sparse_vectors.append(sparse_vec)

        return sparse_vectors


class EmbeddingService:
    """ì„ë² ë”© ì²˜ë¦¬ í†µí•© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, batch_size: int = 256) -> None:
        """
        EmbeddingService ì´ˆê¸°í™”

        Args:
            batch_size: ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
        """
        self.client = MilvusConnectionManager.get_client()
        self.batch_size: int = batch_size

    def process_embedding(self, input_data: EmbeddingInput) -> EmbeddingResult:
        """
        JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ì„ë² ë”© í›„ Milvusì— ì €ì¥

        Args:
            input_data: ì„ë² ë”© ì‘ì—… ì…ë ¥

        Returns:
            ì„ë² ë”© ê²°ê³¼
        """
        start_time: float = time.time()

        try:
            # 1. ë°ì´í„° ë¡œë”©
            logger.info(f"â–¶ï¸ Starting embedding process for collection: {input_data['collection_name']}")
            texts, metadata_list = self._load_data(input_data["json_path"])

            if not texts:
                raise DataValidationError("No valid documents found in JSON file")

            # 2. í¬ì†Œ ë²¡í„° ìƒì„±
            logger.info("Generating sparse vectors (BM25)...")
            tokenized_corpus = [doc.split(" ") for doc in texts]
            sparse_embedder = SparseEmbedder(tokenized_corpus)
            sparse_vectors = sparse_embedder.embed_documents(tokenized_corpus)

            # BM25 ëª¨ë¸ ìºì‹±
            BM25ModelCache.set(input_data["collection_name"], sparse_embedder.bm25)
            logger.info("âœ… Sparse vectors generated and BM25 model cached")

            # 3. ë°€ì§‘ ë²¡í„° ìƒì„±
            logger.info(f"Generating dense vectors ({len(texts)} documents)...")
            dense_embedder = DenseEmbedder(input_data["model_key"])
            dense_vectors = dense_embedder.embed_documents(texts)
            logger.info("âœ… Dense vectors generated")

            # 4. Milvusì— ë°°ì¹˜ ì‚½ì…
            inserted_count = self._batch_insert(
                collection_name=input_data["collection_name"],
                texts=texts,
                metadata_list=metadata_list,
                dense_vectors=dense_vectors,
                sparse_vectors=sparse_vectors,
            )

            elapsed_time = time.time() - start_time
            logger.info(
                f"ğŸ‰ Embedding completed: {inserted_count} documents inserted in {elapsed_time:.2f}s"
            )

            return EmbeddingResult(
                success=True,
                collection_name=input_data["collection_name"],
                total_documents=len(texts),
                inserted_count=inserted_count,
                elapsed_time=elapsed_time,
                message=f"Successfully embedded {inserted_count} documents",
                error=None,
            )

        except (DataValidationError, ModelLoadError, EmbeddingError, Exception) as e:
            elapsed_time = time.time() - start_time
            logger.error(f"âŒ Embedding failed: {e}")

            return EmbeddingResult(
                success=False,
                collection_name=input_data.get("collection_name", ""),
                total_documents=0,
                inserted_count=0,
                elapsed_time=elapsed_time,
                message=None,
                error=str(e),
            )

    def _load_data(self, json_path: str) -> tuple[List[str], List[Dict[str, Any]]]:
        """
        JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”©

        Args:
            json_path: JSON íŒŒì¼ ê²½ë¡œ

        Returns:
            (í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸)

        Raises:
            DataValidationError: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
        """
        if not os.path.exists(json_path):
            raise DataValidationError(f"File not found: {json_path}")

        try:
            with open(json_path, "r", encoding="utf-8") as f:
                items = json.load(f)

            texts: List[str] = []
            metadata_list: List[Dict[str, Any]] = []

            for item in items:
                code = item.get("code")
                if code and code.strip():
                    texts.append(code)
                    metadata_list.append({k: v for k, v in item.items() if k != "code"})

            logger.info(f"Loaded {len(texts)} valid documents from {json_path}")
            return texts, metadata_list

        except json.JSONDecodeError as e:
            raise DataValidationError(f"Invalid JSON format: {e}") from e
        except Exception as e:
            raise DataValidationError(f"Failed to load data: {e}") from e

    def _batch_insert(
        self,
        collection_name: str,
        texts: List[str],
        metadata_list: List[Dict[str, Any]],
        dense_vectors: List[List[float]],
        sparse_vectors: List[Dict[int, float]],
    ) -> int:
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì‚½ì…

        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            metadata_list: ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            dense_vectors: ë°€ì§‘ ë²¡í„° ë¦¬ìŠ¤íŠ¸
            sparse_vectors: í¬ì†Œ ë²¡í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            ì‚½ì…ëœ ë¬¸ì„œ ìˆ˜

        Raises:
            EmbeddingError: ì‚½ì… ì‹¤íŒ¨ ì‹œ
        """
        total_inserted = 0

        for i in range(0, len(texts), self.batch_size):
            batch_end = min(i + self.batch_size, len(texts))
            logger.info(f"  - Inserting batch: {i+1} ~ {batch_end} / {len(texts)}")

            # ë°°ì¹˜ ë°ì´í„° ì¡°ë¦½
            data_to_insert: List[Dict[str, Any]] = []
            for j in range(i, batch_end):
                row = metadata_list[j].copy()
                row["text"] = texts[j]
                row["dense"] = dense_vectors[j]
                row["sparse"] = sparse_vectors[j]
                data_to_insert.append(row)

            # ë°°ì¹˜ ì‚½ì…
            try:
                res = self.client.insert(collection_name=collection_name, data=data_to_insert)
                total_inserted += res["insert_count"]
                logger.info(f"  âœ… Batch inserted successfully (Total: {total_inserted})")

            except Exception as e:
                logger.error(f"âŒ Batch insertion failed at index {i}: {e}")
                raise EmbeddingError(f"Batch insertion failed: {e}") from e

        return total_inserted
