import time, json, os, torch
from typing import List, Dict, Any, Literal

from langchain_community.vectorstores import Milvus
from langchain_core.runnables import RunnableLambda
from pydantic import BaseModel, Field
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
import config
from db_utils import client # MilvusClient ì§ì ‘ ì‚¬ìš©ì„ ìœ„í•´ import

# --- 1. ì„ë² ë”© ì²´ì¸ (Embedding Chain) ---

class EmbeddingInput(BaseModel):
    """ì„ë² ë”© ì²´ì¸ì˜ ì…ë ¥ ëª¨ë¸"""
    json_path: str = Field(description="ë°ì´í„°ê°€ ë‹´ê¸´ JSON íŒŒì¼ ê²½ë¡œ")
    collection_name: str = Field(description="ì €ì¥í•  Milvus ì»¬ë ‰ì…˜ ì´ë¦„")
    model_key: str = Field(default=config.DEFAULT_MODEL_KEY, description="config.pyì— ì •ì˜ëœ ëª¨ë¸ í‚¤")

def _embedding_process(input_data: EmbeddingInput) -> Dict[str, Any]:
    print(f"\nâ–¶ï¸ ì„ë² ë”© ì‹œì‘: [Collection: {input_data.collection_name}, Model Key: {input_data.model_key}]")
    start_time = time.time()

    # --- ë™ì  ëª¨ë¸ ì„¤ì • ë¡œë“œ ---
    model_config = config.EMBEDDING_MODELS.get(input_data.model_key)
    if not model_config:
        return {"error": f"ì„¤ì • íŒŒì¼ì— ì—†ëŠ” ëª¨ë¸ í‚¤ì…ë‹ˆë‹¤: {input_data.model_key}"}
    
    model_name = model_config["model_name"]
    model_kwargs = model_config["kwargs"]
    # ---------------------------

    if not os.path.exists(input_data.json_path):
        return {"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {input_data.json_path}"}
    with open(input_data.json_path, "r", encoding="utf-8") as f:
        items = json.load(f)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    model_kwargs['device'] = device
    
    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs=model_kwargs
    )

    print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. {len(items)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
    
    Milvus.from_texts(
        texts=[json.dumps(item, ensure_ascii=False) for item in items],
        embedding=embeddings,
        collection_name=input_data.collection_name,
        connection_args={"uri": config.MILVUS_URI}
    )
    
    elapsed = time.time() - start_time
    return {
        "success": True,
        "message": f"ğŸ‰ {len(items)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ! (â±ï¸ {elapsed:.2f}ì´ˆ ì†Œìš”)"
    }

embedding_chain = RunnableLambda(_embedding_process)

# --- 2. ê²€ìƒ‰ ì²´ì¸ (Search Chain) ---

class SearchInput(BaseModel):
    """ê²€ìƒ‰ ì²´ì¸ì˜ ì…ë ¥ ëª¨ë¸"""
    query: str
    collection_name: str
    # ğŸ‘‡ ê²€ìƒ‰ ëª¨ë“œ ì¶”ê°€
    search_mode: Literal["hybrid", "vector", "bm25"] = Field(
        default="hybrid", 
        description="ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ"
    )
    model_key: str = Field(default=config.DEFAULT_MODEL_KEY)
    top_k: int = 3
    filter_expression: str | None = None

def get_all_docs_from_collection(collection_name: str) -> List[str]:
    """Milvus ì»¬ë ‰ì…˜ì—ì„œ ëª¨ë“  'text' í•„ë“œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (BM25 ì¸ë±ì‹±ìš©)"""
    if not client.has_collection(collection_name):
        return []
    # MilvusëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ëŠ” ì§ì ‘ì ì¸ ë°©ë²•ì´ ì œí•œì ì´ë¯€ë¡œ
    # ì—¬ê¸°ì„œëŠ” IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°˜ë³µ ì¡°íšŒí•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œëŠ” ì´ ë¶€ë¶„ì„ ìµœì í™”í•´ì•¼ í•©ë‹ˆë‹¤.
    try:
        # ì»¬ë ‰ì…˜ì˜ ì—”í‹°í‹° ìˆ˜ë¥¼ ë¨¼ì € í™•ì¸
        count = client.get_collection_stats(collection_name).get("row_count", 0)
        # ëª¨ë“  IDë¥¼ ì¡°íšŒí•˜ì—¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        results = client.query(
            collection_name=collection_name,
            filter="",
            output_fields=["text"],
            limit=int(count) if count > 0 else 10000 # countê°€ 0ì¼ ê²½ìš° ëŒ€ë¹„
        )
        return [res["text"] for res in results]
    except Exception as e:
        print(f"ì»¬ë ‰ì…˜ ë¬¸ì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def _search_process(input_data: SearchInput) -> List[Dict[str, Any]]:
    """ì„ íƒëœ ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¼ Milvusì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë¡œì§"""
    print(f"\nâ–¶ï¸ ê²€ìƒ‰ ì‹œì‘: [Mode: {input_data.search_mode}, Collection: {input_data.collection_name}]")
    
    # --- 1. Dense Retriever (ë²¡í„° ê²€ìƒ‰) ì¤€ë¹„ ---
    model_config = config.EMBEDDING_MODELS[input_data.model_key]
    embeddings = HuggingFaceEmbeddings(
        model_name=model_config["model_name"],
        model_kwargs=model_config["kwargs"]
    )
    vector_store = Milvus(
        embedding_function=embeddings,
        collection_name=input_data.collection_name,
        connection_args={"uri": config.MILVUS_URI},
    )
    dense_retriever = vector_store.as_retriever(search_kwargs={"k": input_data.top_k})

    # --- 2. Sparse Retriever (BM25) ì¤€ë¹„ (í•„ìš” ì‹œ) ---
    if input_data.search_mode in ["hybrid", "bm25"]:
        # BM25ëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ, Milvusì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
        print("BM25 ì¸ë±ì‹±ì„ ìœ„í•´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
        all_docs = get_all_docs_from_collection(input_data.collection_name)
        if not all_docs:
            print("âš ï¸ BM25 ì¸ë±ì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            if input_data.search_mode == "bm25": return []
            return dense_retriever.invoke(input_data.query)
            
        sparse_retriever = BM25Retriever.from_texts(all_docs)
        sparse_retriever.k = input_data.top_k
    
    # --- 3. ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¼ Retriever ì„ íƒ ë° ì‹¤í–‰ ---
    if input_data.search_mode == "hybrid":
        print("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Ensemble)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        ensemble_retriever = EnsembleRetriever(
            retrievers=[dense_retriever, sparse_retriever], 
            weights=[0.5, 0.5] # ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜, ì¡°ì ˆ ê°€ëŠ¥
        )
        return ensemble_retriever.invoke(input_data.query)

    elif input_data.search_mode == "bm25":
        print("BM25 ë‹¨ë… ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        return sparse_retriever.invoke(input_data.query)
        
    else: # "vector"
        print("ë²¡í„° ë‹¨ë… ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        return dense_retriever.invoke(input_data.query)

def format_docs(docs: List[Any]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not docs:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_list = []
    for i, doc in enumerate(docs):
        formatted_list.append(
            f"  [{i+1}] ë‚´ìš©: {doc.page_content[:200]}..."
        )
    return "\n".join(formatted_list)

search_chain = RunnableLambda(_search_process)