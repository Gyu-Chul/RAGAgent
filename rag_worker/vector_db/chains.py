import time, json, os, torch
from typing import List, Dict, Any

from langchain_community.vectorstores import Milvus
from langchain_core.runnables import RunnableLambda
from pydantic import BaseModel, Field
from langchain_huggingface import HuggingFaceEmbeddings 
import config

# --- 1. ì„ë² ë”© ì²´ì¸ (Embedding Chain) ---

class EmbeddingInput(BaseModel):
    """ì„ë² ë”© ì²´ì¸ì˜ ì…ë ¥ ëª¨ë¸"""
    json_path: str = Field(description="ë°ì´í„°ê°€ ë‹´ê¸´ JSON íŒŒì¼ ê²½ë¡œ")
    collection_name: str = Field(description="ì €ì¥í•  Milvus ì»¬ë ‰ì…˜ ì´ë¦„")
    model_name: str = Field(default=config.DEFAULT_EMBEDDING_MODEL, description="ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸")

def _embedding_process(input_data: EmbeddingInput) -> Dict[str, Any]:
    """JSON íŒŒì¼ì„ ì½ì–´ Milvusì— ì„ë² ë”©í•˜ê³  ì €ì¥í•˜ëŠ” ë¡œì§"""
    print(f"\nâ–¶ï¸ ì„ë² ë”© ì‹œì‘: [Collection: {input_data.collection_name}, Model: {input_data.model_name}]")
    start_time = time.time()

    if not os.path.exists(input_data.json_path):
        return {"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {input_data.json_path}"}
    with open(input_data.json_path, "r", encoding="utf-8") as f:
        items = json.load(f)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    embeddings = HuggingFaceEmbeddings(
        model_name=input_data.model_name,
        model_kwargs={'device': device}
    )

    print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. {len(items)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
    
    Milvus.from_texts(
        texts=[json.dumps(item, ensure_ascii=False) for item in items],
        embedding=embeddings,
        collection_name=input_data.collection_name,
        connection_args={"uri": config.MILVUS_URI},
        primary_field="pk",
        text_field="text",
        vector_field="vector"
    )
    
    elapsed = time.time() - start_time
    return {
        "success": True,
        "message": f"ğŸ‰ {len(items)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ! (â±ï¸ {elapsed:.2f}ì´ˆ ì†Œìš”)"
    }

embedding_chain = RunnableLambda(_embedding_process)

# --- 2. ê²€ìƒ‰ ì²´ì¸ (Search Chain) ---

class SearchInput(BaseModel):
    """ê²€ìƒ‰ ì²´ì¸ì˜ ì…ë ¥ ëª¨ë¸"""
    query: str
    collection_name: str
    model_name: str = Field(default=config.DEFAULT_EMBEDDING_MODEL)
    top_k: int = 3
    filter_expression: str | None = None

def _search_process(input_data: SearchInput) -> List[Dict[str, Any]]:
    """Milvusì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë¡œì§"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    embeddings = HuggingFaceEmbeddings(
        model_name=input_data.model_name,
        model_kwargs={'device': device}
    )
    
    vector_store = Milvus(
        embedding_function=embeddings,
        collection_name=input_data.collection_name,
        connection_args={"uri": config.MILVUS_URI},
        primary_field="pk",
        text_field="text",
        vector_field="vector"
    )
    
    search_kwargs = {"k": input_data.top_k}
    if input_data.filter_expression:
        search_kwargs["expr"] = input_data.filter_expression
        
    retriever = vector_store.as_retriever(search_kwargs=search_kwargs)
    
    return retriever.invoke(input_data.query)

def format_docs(docs: List[Any]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not docs:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_list = []
    for i, doc in enumerate(docs):
        formatted_list.append(
            f"  [{i+1}] ë‚´ìš©: {doc.page_content[:200]}..."
        )
    return "\n".join(formatted_list)

search_chain = RunnableLambda(_search_process)