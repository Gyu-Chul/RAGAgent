# **LLM 질의응답 서비스 (LLM Call Service)**

마지막으로 최종 결과물을 만들어내는 역할을 담당합니다. 벡터 DB에서 검색된 코드 조각(컨텍스트)과 사용자의 질문을 바탕으로, 향상된 프롬프트를 생성하고 이를 OpenAI의 대규모 언어 모델(LLM)에 전송하여 최종 답변을 얻어냅니다.

## **핵심 기술 및 아키텍처**

이 서비스의 핵심은 **RAG(Retrieval-Augmented Generation, 검색 증강 생성)** 패러다임의 '생성(Generation)' 단계를 구현하는 데 있습니다. LLM이 가진 방대한 지식에 의존하는 대신, 주어진 컨텍스트(검색된 코드) 내에서만 답변하도록 제한하여 **환각(Hallucination)을 방지**하고, **정확성과 신뢰도를 극대화**하는 것이 핵심 목표입니다.

### **프롬프트 엔지니어링 (Prompt Engineering)**

본 서비스의 성능은 LLM에게 전달되는 프롬프트의 품질에 크게 좌우됩니다. 이를 위해 두 가지 핵심 프롬프트를 전략적으로 결합합니다.

1. **시스템 프롬프트 (System Prompt)**: AI의 역할, 행동 지침, 분석 방법론을 정의하는 '명령서'입니다.  
   * **역할 부여**: "AI 코드 분석 전문가"라는 명확한 페르소나를 부여합니다.  
   * **작업 절차 정의**: 컨텍스트를 이해하고, 관련성 점수(score)를 기반으로 정보를 선별한 뒤, 종합적으로 추론하여 답변을 생성하는 체계적인 절차를 따르도록 지시합니다.  
   * **규칙 설정**: 답변은 반드시 컨텍스트에 근거해야 하며, 근거가 된 코드를 명시하도록 강제합니다. 정보가 부족할 경우 추측하지 않고 솔직하게 인정하도록 하여 답변의 신뢰도를 높입니다.  
2. **사용자 프롬프트 (User Prompt)**: 실제 검색된 코드와 사용자 질문을 담는 '데이터'입니다.  
   * Vector DB에서 검색된 코드 조각들이 가독성 높은 형식으로 포맷팅되어 컨텍스트로 제공됩니다.  
   * 각 코드 조각에는 파일 경로, 모듈 정보, 그리고 가장 중요한 \*\*관련성 점수(score)\*\*가 명시되어, LLM이 정보의 중요도를 판단하는 데 결정적인 단서로 사용됩니다.

## **주요 기능 및 구성 요소**

### **1\. PromptGenerator: 프롬프트 생성기**

* **역할**: Vector DB로부터 받은 검색 결과(코드 조각 리스트)와 사용자 질문을 조합하여, LLM이 가장 잘 이해할 수 있는 형태의 최종 '사용자 프롬프트'를 생성합니다.  
* **주요 기능**:  
  * **구조화된 컨텍스트**: 각 코드 조각을 단순 텍스트가 아닌, 출처, 파일 경로, 모듈 정보, 관련성 점수 등 메타데이터가 포함된 구조적인 형태로 포맷팅합니다.  
  * **가독성**: 코드 블록을 Markdown 형식으로 감싸 LLM이 코드와 일반 텍스트를 명확히 구분하도록 돕습니다.

### **2\. AskQuestion: API 통신 모듈**

* **역할**: 생성된 프롬프트를 LLM API로 전송하고, 응답을 받아오는 모든 통신 과정을 담당합니다.  
* **주요 기능**:  
  * **강력한 시스템 프롬프트 내장**: 위에서 설명한 정교한 시스템 프롬프트가 내장되어 있어, 모든 요청에 일관된 행동 지침을 AI에 전달합니다.  
  * **API 관리**: 환경 변수(.env)에서 API 키를 안전하게 로드하고, API 호출 시 발생할 수 있는 오류를 처리합니다.  
  * **유연한 옵션**: 스트리밍 응답, 모델 선택(gpt-4o-mini 등), temperature(창의성), max\_tokens(최대 길이) 등 다양한 파라미터를 지원합니다.

### **3\. AskCaller: 통합 서비스 인터페이스**

* **역할**: PromptGenerator와 AskQuestion을 하나로 묶어, 개발자가 단 한 번의 호출로 "검색 결과 → 최종 답변" 과정을 실행할 수 있도록 단순화된 인터페이스를 제공합니다.

## **동작 과정 (Workflow)**

1. **(입력)** VectorDBService로부터 받은 \*\*검색 결과(docs)\*\*와 \*\*사용자 질문(query)\*\*을 AskCaller에게 전달합니다.  
2. AskCaller는 이 입력값을 **PromptGenerator** 로 넘깁니다.  
3. **PromptGenerator** 는 검색된 각 코드 조각을 관련성 점수, 파일 경로 등의 메타데이터와 함께 보기 좋은 형식으로 묶어 하나의 거대한 **컨텍스트(context) 문자열**을 만듭니다.  
4. 이 컨텍스트와 사용자 질문을 템플릿에 결합하여 최종 \*\*사용자 프롬프트(user\_prompt)\*\*를 완성합니다.  
5. AskCaller는 완성된 user\_prompt를 **AskQuestion** 모듈로 전달합니다.  
6. **AskQuestion** 모듈은 미리 정의된 \*\*시스템 프롬프트(system\_prompt)\*\*와 전달받은 user\_prompt를 함께 OpenAI API로 전송합니다.  
7. LLM은 주어진 역할과 규칙(시스템 프롬프트)에 따라, 제공된 컨텍스트(사용자 프롬프트)를 분석하여 질문에 대한 답변을 생성합니다.  
8. **AskQuestion** 모듈이 LLM의 응답을 받아 AskCaller를 통해 최종 사용자에게 전달하며 프로세스가 종료됩니다.
